config:
  email:
    sender: "example@gmail.com"
    receiver: "example@gmail.com"
    password: "password"
  elastic_save:
    username: "debatelab"
    password: "password"
    host: "143.233.226.60"
    port: 9200
    connect: "key" # options: key, password
    ssh:
      port: 222
      username: "debatelab"
      password: "password"
      key_path: "/path/to/key"
  elastic_retrieve:
    username: "elastic"
    password: "password"
    host: "socialwebobservatory.iit.demokritos.gr"
    port: 9200
    connect: "password" # options: password, key
    ssh:
      port: 222
      username: "debatelab"
      password: "password"
      key_path: "/path/to/key"
  adu_data:
    train_csv: "train_adu.csv"
    dev_csv: "dev_adu.csv"
    test_csv: "test_adu.csv"
  rel_data:
    train_csv: "train_rel.csv"
    dev_csv: "dev_rel.csv"
    test_csv: "test_rel.csv"
  stance_data:
    train_csv: "train_stance.csv"
    dev_csv: "dev_stance.csv"
    test_csv: "test_stance.csv"
  sim_data:
    train_csv: "train_sim.csv"
    dev_csv: "train_sim.csv"
    test_csv: "train_sim.csv"
tasks: ["prep", "train", "eval"]
preprocessing:
  other_label: "O"
  repl_char: "="
  max_len: 512
  pad_token: 0
train:
  models: ["adu", "rel", "stance", "sim"]
eval:
  model: "best" # options: best, final
  retrieve: "file" # options: file, date
  last_date: ""
  ner_endpoint: "http://petasis.dyndns.org:7100/predict-ner"
  max_correction_tries: 3
  notify:
    url_arg_mining: "https://isl.ics.forth.gr/debatelab_mq/api/exchanges/dlab/amq.default/publish"
    url_clustering: "https://isl.ics.forth.gr/debatelab_mq/api/exchanges/dlab/amq.default/publish"
    username: "debateLab3ServerUser"
    password: "debateLabPassw0rd"
seq_model:
  bert_kind:
    adu: ["aueb"] # base, nli, aueb
  hidden_size: 256
  rnn_layers: 2
  dropout: 0.5
  use_crf: True
  learning_rate: 0.0001
  mini_batch_size: 32
  num_workers: 8
  max_epochs: 150
  patience: 10
  optimizer: Adam
  use_tensorboard: True
  train_with_dev: False
  save_final_model: True
  shuffle: False
class_model:
  bert_kind:
    rel: ["aueb"] # base, nli, aueb, base-multi
    stance: ["aueb"] # base, nli, aueb, base-multi
    sim: ["multi-nli", "nli"] # base, nli, aueb, base-multi, multi-nli
  hidden_size: 256
  layers: 2
  use_crf: False
  learning_rate: 0.0001
  mini_batch_size: 32
  num_workers: 8
  max_epochs: 150
  patience: 10
  optimizer: Adam
  use_tensorboard: True
  train_with_dev: False
  save_final_model: True
  shuffle: False
clustering:
  n_clusters: 10
  bert_kind: "aueb" # aueb, base, nli